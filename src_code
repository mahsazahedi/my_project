import time
import math
import torchvision
import torch
import torchvision.transforms as transforms
import os
import matplotlib.pyplot as plt
import numpy as np
import torchvision.models as models
import torch.nn as nn
import torch.optim as optim
import torch.nn.utils.prune as prune
import torch.nn.functional as F
from torch.nn.modules.module import Module
from torch.nn import Parameter
import argparse
from torch.cuda import amp
#import torch.cuda.profiler as profiler
#import torch.cuda.nvtx as nvtx
#import pyprof
#pyprof.init()
import subprocess
#import nvsmi
import torch
from torch import nn
from torch import Tensor
from torch.autograd import Variable
torch.backends.cudnn.deterministic = True
#@title Default title text
print('==> Preparing data..')
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)

test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

def show_transformed_images(dataset):
     loader = torch.utils.data.DataLoader(dataset, batch_size=6, shuffle=True)
     batch = next(iter(loader))
     images, labels = batch

     grid = torchvision.utils.make_grid(images, nrow=3)
     plt.figure(figsize=(11, 11))
     plt.imshow(np.transpose(grid, (1, 2, 0)))
     print('labels: ', labels)
show_transformed_images(train_dataset)

def set_device():
    if torch.cuda.is_available():
        dev = "cuda"
    else:
        dev = 'cpu'
    return torch.device(dev)

device = set_device()
device
import torch.nn.utils.prune as prune

def prune_model(model, pruning_method=prune.L1Unstructured, amount=0.3):

    parameters_to_prune = []
    for module in model.modules():
        if isinstance(module, torch.nn.Conv2d):
            parameters_to_prune.append((module, 'weight'))

    for module, parameter_name in parameters_to_prune:
        prune.global_unstructured(
             parameters_to_prune,
             pruning_method=prune.L1Unstructured,
             amount=0.3,
            )
        # Convert pruned weights to zeros
        pruned_mask = getattr(module, parameter_name + "_mask")
        module.weight.data *= pruned_mask
        
        for module, _ in parameters_to_prune:
          prune.remove(module, 'weight')
          print(list(module.named_parameters()))

    return model
def get_total_parameters_count(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)
def print_model_parameters(model, with_values=False):
    print(f"{'Param name':20} {'Shape':30} {'Type':15}")
    print('-'*70)
    for name, param in model.named_parameters():
        print(f'{name:20} {str(param.shape):30} {str(param.dtype):15}')
        if with_values:
            print(param)
def print_nonzeros(model):
    nonzero = total = 0
    for name, p in model.named_parameters():
        if 'mask' in name:
            continue
        tensor = p.data.cpu().numpy()
        nz_count = np.count_nonzero(tensor)
        total_params = np.prod(tensor.shape)
        nonzero += nz_count
        total += total_params
        print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')
    print(f'alive: {nonzero}, pruned : {total - nonzero}, total: {total}, Compression rate : {total/nonzero:10.2f}x  ({100 * (total-nonzero) / total:6.2f}% pruned)')
 def get_pruned_parameters_count(pruned_model):
    params = 0
    for param in pruned_model.parameters():
        if param is not None:
            params += (param == 0).sum().item()  # Count the number of 0-valued parameters
    return params
 def col2im(mul, h_prime, w_prime, C):
    """
    Args:
        mul: (h_prime * w_prime * w, F) matrix, each col
             should be reshaped to C * h_prime * w_prime when C > 0, or
             h_prime * w_prime when C = 0
        h_prime: reshaped filter height
        w_prime: reshaped filter width
        C: reshaped filter channel, if 0, reshape the filter
           to 2D, Otherwise reshape it to 3D
    Returns:
        if C == 0: (F, h_prime, w_prime) matrix
        Otherwise: (F, C, h_prime, w_prime) matrix
    """
    F = mul.shape[1]
    if C == 0:
        out = torch.zeros([F, h_prime, w_prime])
        for i in range(F):
            col = mul[:, i]
            out[i, :, :] = torch.reshape(col, (h_prime, w_prime))
    else:
        out = torch.zeros([F, C, h_prime, w_prime])
        for i in range(F):
            col = mul[:, i]
            out[i, :, :] = torch.reshape(col, (C, h_prime, w_prime))

    return out
def im2col(x, hh, ww, stride):
    """
    Args:
        x: image matrix to be translated into columns, (C,H,W)
        hh: filter height
        ww: filter width
        stride: stride, a tuple of two values (stride_height, stride_width)
    Returns:
        col: (new_h*new_w,hh*ww*C) matrix, each column is a cube that will convolve with a filter
        new_h = (H-hh) // stride[0] + 1, new_w = (W-ww) // stride[1] + 1
    """

    c, h, w = x.shape
    stride_height, stride_width = stride
    new_h = (h - hh) // stride[0] + 1
    new_w = (w - ww) // stride[1] + 1

    col = torch.zeros([new_h * new_w, c * hh * ww], dtype=x.dtype, device=x.device)

    for i in range(new_h):
        for j in range(new_w):
            patch = x[..., (i * stride[0]):(i * stride[1] + hh), (j * stride[1]):(j * stride[1] + ww)]
            col[i * new_w + j, :] = torch.reshape(patch, (-1,))
    return col
import scipy.sparse as sp

def sparse_matmul_tensorcore(a, b):
    a = a.cpu().detach().numpy()
    b= b.cpu().detach().numpy()
    # Convert sparse matrix A to CSR format
    a_csr = sp.csr_matrix(a)

    # Extract the CSR format data
    indices = torch.tensor(a_csr.indices, dtype=torch.int32).cuda()
    indptr = torch.tensor(a_csr.indptr, dtype=torch.int32).cuda()
    values = torch.tensor(a_csr.data, dtype=torch.float16).cuda()

    M, N = a.shape
    N, K = b.shape

    # Determine the block size for matrix multiplication
    block_size = 16

    # Allocate memory for output matrix C
    c = torch.zeros((M, K), dtype=torch.float16).cuda()

    # Enable Tensor Cores for mixed-precision matrix multiplication
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cuda.matmul.autocast_mode = 'TF32'

    # Loop over the blocks of matrices A and B
    for m in range(0, M, block_size):
        for k in range(0, K, block_size):
            for n in range(0, N, block_size):
                # Extract block of size 16x16 from A and B
                a_block_indices = indices[indptr[m]:indptr[min(m+block_size, M)]]
                a_block_values = values[indptr[m]:indptr[min(m+block_size, M)]]
                a_block = torch.sparse_coo_tensor(a_block_indices, a_block_values,
                                                  (min(m+block_size, M), N)).to_dense()
                b_block = b[n:min(n+block_size, N), k:min(k+block_size, K)]

                # Perform matrix multiplication using torch.mm() with Tensor Cores
                c_block = torch.mm(a_block, b_block)

                # Accumulate the results in output matrix C
                c[m:min(m+block_size, M), k:min(k+block_size, K)] += c_block

    # Disable Tensor Cores
    torch.backends.cuda.matmul.allow_tf32 = False
    torch.backends.cuda.matmul.autocast_mode = 'FP32'
    c = torch.tensor(c)

    return c
import torch
import torch.nn as nn
from torch import Tensor
from torch.nn.modules.utils import _pair
class DeformableConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, dilation=1, bias=True,groups=1):
        super(DeformableConv2d, self).__init__()  
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.pad_num = padding
        self.kernel_size = _pair(kernel_size)
        self.stride = _pair(stride)
        self.padding = _pair(padding)
        self.dilation = _pair(dilation)
        self.conv_param = {'stride': self.stride , 'pad': self.pad_num}
        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size), requires_grad=True)
        nn.init.xavier_uniform_(self.weight, gain=nn.init.calculate_gain('relu'))
        self._reset_parameters()  # Call the _reset_parameters function
        self.groups = groups
        self.bias = bias

    def _reset_parameters(self):
        """Reset the parameters of the convolutional layer."""
        nn.init.xavier_uniform_(self.weight, gain=nn.init.calculate_gain('relu'))

    def conv_forward_naive(self, input: Tensor, weight: Tensor, bias: Tensor):
        x = input
        out = None
        ww = self.kernel_size
        hh = self.kernel_size
        b = self.bias
        weight = self.weight
        stride = self.conv_param['stride']
        pad_num = self.conv_param['pad']
        conv_param = self.conv_param
        N, C, H, W = x.shape
        F, C, HH, WW = weight.shape
        H_prime = (H + 2 * pad_num - HH) // stride[0] + 1
        W_prime = (W + 2 * pad_num - WW) // stride[1] + 1

        out = torch.zeros([N, F, H_prime, W_prime])
        # im2col
        for im_num in range(N):
            im = x[im_num, :, :, :].to(device)
            im_pad = torch.nn.functional.pad(im, (pad_num, pad_num, pad_num, pad_num), 'constant', 0).to(device)
            im_col = im2col(im_pad, HH, WW, stride).to(device)
            filter_col = torch.reshape(weight, (F, -1)).to(device)
            mul = sparse_matmul_tensorcore(im_col, filter_col.T).to(device)
            mull = torch.add(mul, b).to(device)
            out[im_num, :, :, :] = col2im(mull, H_prime, W_prime, 1).to(device)
          
        return out.float()

    def forward(self, input: Tensor):
        if input.dim() == 4:
            return self.conv_forward_naive(input, self.weight, self.bias).to(device)
        elif input.dim() < 4:
            # Reshape input to have 4 dimensions
            while input.dim() < 4:
                input = input.unsqueeze(0)
            output = self.conv_forward_naive(input, self.weight, self.bias).to(device)
            # Remove extra dimensions from output
            while output.dim() > input.dim():
                output = output.squeeze(0)
            return output


    def _pair(self, val):
        if isinstance(val, int):
            return (val, val)
        else:
            return val
def train(model, train_loader, criterion, optimizer, n_epochs, scaler):
    since = time.time()
    device = set_device()
    model.train()
    train_losses = []  # List to store the training losses for each epoch
    train_accuracies = []  # List to store the training accuracies for each epoch
    for epoch in range(n_epochs):
        train_loss = 0
        correct = 0
        total = 0
        for batch_idx, (inputs, targets) in enumerate(train_loader):
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()

            with torch.cuda.amp.autocast():
                output = model(inputs)
                loss = criterion(output, targets)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            train_loss += loss.item()
            _, predicted = output.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

        epoch_loss = train_loss / (batch_idx + 1)
        epoch_accuracy = 100. * correct / total
        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_accuracy)

        print('\nEpoch: %d' % epoch, " Loss: %.3f | Acc: %.3f%% (%d/%d)"
              % (train_loss / (batch_idx + 1), 100. * correct / total, correct, total))
    time_elapsed = time.time() - since
    print("training complete in {:.0f}m {:.0f}s".format(
        time_elapsed // 60, time_elapsed % 60
    ))

    # Plotting the loss and accuracy curves
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.plot(range(1, n_epochs + 1), train_losses, color="r")
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training Loss')

    plt.subplot(1, 2, 2)
    plt.plot(range(1, n_epochs + 1), train_accuracies, color="b")
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.title('Training Accuracy')

    plt.show()

    return model





# Commented out IPython magic to ensure Python compatibility.
def evaluate_model_on_test_set(model, test_loader,criterion):
    since = time.time()
    model.eval()
    device = set_device()

    test_loss = 0
    correct = 0
    total = 0
    loss_list = []
    accuracy_list = []
    with torch.no_grad():
      for batch_idx, (inputs, targets) in enumerate(test_loader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

             # Append loss and accuracy to lists for plotting
            loss_list.append(loss.item())
            accuracy_list.append(predicted.eq(targets).sum().item() / targets.size(0))

    test_loss /= (batch_idx + 1)
    test_accuracy = 100. * correct / total

    print("Loss: %.3f | Acc: %.3f%% (%d/%d)"
            % (test_loss, test_accuracy, correct, total))

    time_elapsed = time.time() - since
    print("Testing complete in {:.0f}m {:.0f}s".format(
        time_elapsed // 60, time_elapsed % 60
    ))

    # Plot loss and accuracy
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.plot(loss_list,color="r")
    plt.xlabel('Iteration')
    plt.ylabel('Loss')
    plt.title('Test Loss Over Time')
    plt.subplot(1, 2, 2)
    plt.plot(accuracy_list,color="b")
    plt.xlabel('Iteration')
    plt.ylabel('Accuracy')
    plt.title('Test Accuracy Over Time')
    plt.show()


import torch
import torch.nn as nn
from torchvision.models import resnet50
from torch.cuda.amp import autocast


class DeformableResNet50(nn.Module):
    def __init__(self, num_classes=1000):
        super(DeformableResNet50, self).__init__()
        resnet = resnet50(pretrained=True)

        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        self.layer1 = resnet.layer1
        self.layer2 = resnet.layer2
        self.layer3 = resnet.layer3
        self.layer4 = resnet.layer4

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.deformable_conv = DeformableConv2d(2048, num_classes, kernel_size=1)

    @autocast()
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.deformable_conv(x)

        return x

    @autocast
    def forward_amp(self, x):
        return self.forward(x)
resnet_model =  DeformableResNet50().to(device)


print(resnet_model)
print_model_parameters(resnet_model)
total_params_count = get_total_parameters_count(resnet_model)
print("total_params_count : ",total_params_count)


loss_fn = nn.CrossEntropyLoss()

optimizer = optim.Adam(resnet_model.parameters(), lr=0.01)

scaler = torch.cuda.amp.GradScaler()

print("--- Initial training ---")
Model=train(resnet_model, train_loader, loss_fn, optimizer, 50,scaler)
evaluate_model_on_test_set(Model, test_loader,loss_fn)
total_params_count = get_total_parameters_count(Model)
print("--- Before pruning ---")
print("total_params_count : ",total_params_count)
print_nonzeros(Model)
print("pruned_parameters_count : ",get_pruned_parameters_count(Model))

# Pruning
Model_prune = prune_model(Model)
evaluate_model_on_test_set(Model_prune, test_loader,loss_fn)
total_params_count = get_total_parameters_count(Model_prune)
print("--- After pruning ---")
print("total_params_count : ",total_params_count)
print_nonzeros(Model_prune)
print("pruned_parameters_count : ",get_pruned_parameters_count(resnet_model))


# Retrain
print("--- Retraining ---")
initial_optimizer_state_dict = optimizer.state_dict()
optimizer.load_state_dict(initial_optimizer_state_dict) # Reset the optimizer
Model2=train(Model_prune, train_loader, loss_fn, optimizer, 50,scaler)
evaluate_model_on_test_set(Model2, test_loader,loss_fn)
total_params_count = get_total_parameters_count(Model2)
print("--- After Retraining ---")
print("total_params_count : ",total_params_count)
print_nonzeros(Model)
print("pruned_parameters_count : ",get_pruned_parameters_count(Model2))
